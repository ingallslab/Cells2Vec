{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *\n",
    "from losses import *\n",
    "net = load_model_from_checkpoint(\n",
    "    'PATH_TO_CHECKPOINT')\n",
    "device ='cuda'\n",
    "net= net.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import os\n",
    "import torch\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "directory = 'PATH_TO_FOLDER_WITH_EXP_DATA'\n",
    "scaler = StandardScaler()\n",
    "\n",
    "folders = [folder for folder in os.listdir(\n",
    "    directory) if os.path.isdir(os.path.join(directory, folder))]\n",
    "\n",
    "final_tensors = []\n",
    "exp_tensors = []\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(directory, folder)\n",
    "\n",
    "    pickle_files = [file for file in os.listdir(\n",
    "        folder_path) if file.endswith('.pickle')]\n",
    "\n",
    "    tensor_list = []\n",
    "\n",
    "    count_large = 0\n",
    "\n",
    "    for pickle_file in pickle_files:\n",
    "\n",
    "        pickle_to_dict = np.load(os.path.join(\n",
    "            folder_path, pickle_file), allow_pickle=True)\n",
    "\n",
    "        df = make_numpy_array(pickle_to_dict)\n",
    "\n",
    "        i, j = df.shape[0], df.shape[1]\n",
    "\n",
    "        df = scaler.fit_transform(df.view(-1, 1))\n",
    "        df = torch.tensor(df).view(i, j)\n",
    "       \n",
    "        tensor_list.append(df)\n",
    "\n",
    "    tensored_stuff = torch.cat(tensor_list, dim=0)\n",
    "    exp_tensors.append(tensored_stuff)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "device= torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "output_embeddings=[]\n",
    "for i in exp_tensors:\n",
    "    i =i.transpose(1,0).unsqueeze(0).float().to(device)\n",
    "    output_embeddings.append(net(i).detach().cpu().numpy())\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13, 4)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_embeddings=np.array(output_embeddings).squeeze()\n",
    "output_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "directory = 'PATH_TO_FOLDER_WITH_SIM_DATA'\n",
    "scaler = StandardScaler()\n",
    "\n",
    "folders = [folder for folder in os.listdir(\n",
    "    directory) if os.path.isdir(os.path.join(directory, folder))]\n",
    "\n",
    "final_tensors = []\n",
    "exp_tensors_sims = []\n",
    "\n",
    "\n",
    "for folder in folders:\n",
    "    folder_path = os.path.join(directory, folder)\n",
    "    #print(folder_path)\n",
    "\n",
    "    pickle_files = [file for file in os.listdir(\n",
    "        folder_path) if file.endswith('.pickle')]\n",
    "\n",
    "    tensor_list = []\n",
    "\n",
    "    count_large = 0\n",
    "\n",
    "    for pickle_file in pickle_files:\n",
    "\n",
    "        pickle_to_dict = np.load(os.path.join(\n",
    "            folder_path, pickle_file), allow_pickle=True)\n",
    "\n",
    "        df = make_numpy_array(pickle_to_dict)\n",
    "\n",
    "        i, j = df.shape[0], df.shape[1]\n",
    "\n",
    "        df = scaler.fit_transform(df.view(-1, 1))\n",
    "        df = torch.tensor(df).view(i, j)\n",
    "        #print(df.shape)\n",
    "        tensor_list.append(df)\n",
    "\n",
    "    tensored_stuff = torch.cat(tensor_list, dim=0)\n",
    "    exp_tensors_sims.append(tensored_stuff)\n",
    "    #\n",
    "    # tensor_tensor_list.append(tensored_stuff)\n",
    "    #arr=np.load('exp.npy', allow_pickle=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the length distribution of Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8733\n",
      "3893.5384615384614\n"
     ]
    }
   ],
   "source": [
    "len_counter = []\n",
    "for i in exp_tensors:\n",
    "    length = i.shape[0]\n",
    "    len_counter.append(length)\n",
    "\n",
    "max_len = max(len_counter)\n",
    "print(max_len)\n",
    "print(np.array(len_counter).mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Checking the length distribution of Simulations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1377\n",
      "1198.0\n"
     ]
    }
   ],
   "source": [
    "len_counter = []\n",
    "for i in exp_tensors_sims:\n",
    "    length = i.shape[0]\n",
    "    len_counter.append(length)\n",
    "\n",
    "max_len = max(len_counter)\n",
    "print(max_len)\n",
    "print(np.array(len_counter).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_embeddings_sims = []\n",
    "for i in exp_tensors_sims:\n",
    "    i = i.transpose(1, 0).unsqueeze(0).float().to(device)\n",
    "    output_embeddings_sims.append(net(i).detach().cpu().numpy())\n",
    "\n",
    "output_embeddings_sims = np.array(output_embeddings_sims).squeeze()\n",
    "output_embeddings_sims.shape\n",
    "\n",
    "# Ensure that a particular order is maintained for exps and sims\n",
    "\n",
    "order =[12,6,3,0,2,8,11,7,10,4,5,9,1]\n",
    "output_embeddings_sims = output_embeddings_sims[order]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_45183/716125333.py:5: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  similarity = torch.tensor(F.cosine_similarity(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9479733201173636"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores = []\n",
    "for i in range(13):\n",
    "    sim = torch.tensor(output_embeddings[i]) \n",
    "    exp = torch.tensor(output_embeddings_sims[i])\n",
    "    similarity = torch.tensor(F.cosine_similarity(\n",
    "        sim.unsqueeze(0), exp.unsqueeze(0), dim=1))\n",
    "\n",
    "\n",
    "    similarity_scores.append(similarity.item())\n",
    "\n",
    "np.mean(similarity_scores)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scaling Experiments And Simulations (Embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler=StandardScaler()\n",
    "scaled_embeds_exp=[]\n",
    "scaled_embeds_sims=[]\n",
    "for i in output_embeddings:\n",
    "    j=scaler.fit_transform(i.reshape(-1,1))\n",
    "    scaled_embeds_exp.append(j)\n",
    "\n",
    "for i in output_embeddings_sims:\n",
    "    j=scaler.fit_transform(i.reshape(-1,1))\n",
    "    scaled_embeds_sims.append(j)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Euclidean Similarity for normalized inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6612705680040213"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similarity_scores = []\n",
    "for i in range(13):\n",
    "    sim = torch.tensor(scaled_embeds_exp[i]) \n",
    "    exp = torch.tensor(scaled_embeds_sims[i])\n",
    "\n",
    "    euclidean_distance = torch.norm(\n",
    "        sim - exp, p=2)  \n",
    "\n",
    "    similarity_scores.append(similarity.item())\n",
    "    similarity = 1/(1+euclidean_distance)\n",
    "\n",
    "np.mean(similarity_scores)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
